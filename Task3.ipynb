{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and get data as letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Active  0  1  2  3\n",
      "0           0  D  K  W  L\n",
      "1           0  F  C  H  N\n",
      "2           0  K  D  Q  P\n",
      "3           0  F  N  W  I\n",
      "4           0  N  K  R  M\n",
      "...       ... .. .. .. ..\n",
      "49995       0  K  P  P  Q\n",
      "49996       0  E  K  M  V\n",
      "49997       0  A  K  S  L\n",
      "49998       0  W  Y  D  P\n",
      "49999       0  S  C  Q  P\n",
      "\n",
      "[50000 rows x 5 columns]\n",
      "       0  1  2  3\n",
      "0      H  W  F  K\n",
      "1      M  W  P  W\n",
      "2      A  L  D  V\n",
      "3      N  T  L  G\n",
      "4      L  H  Y  Y\n",
      "...   .. .. .. ..\n",
      "47995  N  R  W  M\n",
      "47996  M  M  M  K\n",
      "47997  A  F  N  M\n",
      "47998  C  R  Y  I\n",
      "47999  M  K  F  C\n",
      "\n",
      "[48000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test = True\n",
    "\n",
    "x_train = pd.read_csv('train.csv')\n",
    "\n",
    "x_train = x_train[0:50000]\n",
    "\n",
    "letters = x_train['Sequence'].apply(lambda x: pd.Series(list(x)))\n",
    "x_train = x_train.drop('Sequence', axis = 1)\n",
    "x_train = x_train.join(letters)\n",
    "print(x_train)\n",
    "\n",
    "if test:\n",
    "    x_test = pd.read_csv('test.csv')\n",
    "    letters = x_test['Sequence'].apply(lambda x: pd.Series(list(x)))\n",
    "    x_test = x_test.drop('Sequence', axis = 1)\n",
    "    x_test = x_test.join(letters)\n",
    "    print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Active  0_A  0_C  0_D  0_E  0_F  0_G  0_H  0_I  0_K  ...  3_M  3_N  \\\n",
      "0           0    0    0    1    0    0    0    0    0    0  ...    0    0   \n",
      "1           0    0    0    0    0    1    0    0    0    0  ...    0    1   \n",
      "2           0    0    0    0    0    0    0    0    0    1  ...    0    0   \n",
      "3           0    0    0    0    0    1    0    0    0    0  ...    0    0   \n",
      "4           0    0    0    0    0    0    0    0    0    0  ...    1    0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "49995       0    0    0    0    0    0    0    0    0    1  ...    0    0   \n",
      "49996       0    0    0    0    1    0    0    0    0    0  ...    0    0   \n",
      "49997       0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "49998       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "49999       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "\n",
      "       3_P  3_Q  3_R  3_S  3_T  3_V  3_W  3_Y  \n",
      "0        0    0    0    0    0    0    0    0  \n",
      "1        0    0    0    0    0    0    0    0  \n",
      "2        1    0    0    0    0    0    0    0  \n",
      "3        0    0    0    0    0    0    0    0  \n",
      "4        0    0    0    0    0    0    0    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "49995    0    1    0    0    0    0    0    0  \n",
      "49996    0    0    0    0    0    1    0    0  \n",
      "49997    0    0    0    0    0    0    0    0  \n",
      "49998    1    0    0    0    0    0    0    0  \n",
      "49999    1    0    0    0    0    0    0    0  \n",
      "\n",
      "[50000 rows x 81 columns]\n",
      "       0_A  0_C  0_D  0_E  0_F  0_G  0_H  0_I  0_K  0_L  ...  3_M  3_N  3_P  \\\n",
      "0        0    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n",
      "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2        1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4        0    0    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "47995    0    0    0    0    0    0    0    0    0    0  ...    1    0    0   \n",
      "47996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "47997    1    0    0    0    0    0    0    0    0    0  ...    1    0    0   \n",
      "47998    0    1    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "47999    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "       3_Q  3_R  3_S  3_T  3_V  3_W  3_Y  \n",
      "0        0    0    0    0    0    0    0  \n",
      "1        0    0    0    0    0    1    0  \n",
      "2        0    0    0    0    1    0    0  \n",
      "3        0    0    0    0    0    0    0  \n",
      "4        0    0    0    0    0    0    1  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  \n",
      "47995    0    0    0    0    0    0    0  \n",
      "47996    0    0    0    0    0    0    0  \n",
      "47997    0    0    0    0    0    0    0  \n",
      "47998    0    0    0    0    0    0    0  \n",
      "47999    0    0    0    0    0    0    0  \n",
      "\n",
      "[48000 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_oh = pd.get_dummies(data=x_train, columns=[0, 1, 2, 3], sparse=True)\n",
    "print(x_train_oh)\n",
    "\n",
    "if test:\n",
    "    x_test_oh = pd.get_dummies(data=x_test, columns=[0, 1, 2, 3], sparse=True)\n",
    "    print(x_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix unbalanced data for better performance. Easiest is to oversample the 1's. Its worth a shot at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Neural network <-- there is documentation in scikit\n",
    "l1_size = int(0.006 * x_train_oh.shape[0])\n",
    "l2_size = int(0.008 * x_train_oh.shape[0])\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(l1_size, l2_size), random_state=1, activation='tanh', max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8964241676942046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761194029850748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-6a2fb071fe73>\", line 5, in <module>\n",
      "    pred = clf.predict(x_train_oh.iloc[test_indices, 1:])\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 971, in predict\n",
      "    y_pred = self._predict(X)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 685, in _predict\n",
      "    self._forward_pass(activations)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 109, in _forward_pass\n",
      "    activations[i + 1] = hidden_activation(activations[i + 1])\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py\", line 59, in tanh\n",
      "    return np.tanh(X, out=X)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/martinbrandt/opt/anaconda3/lib/python3.7/posixpath.py\", line 351, in normpath\n",
      "    if path == empty:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "f1_scores = []\n",
    "for train_indices, test_indices in kf.split(x_train):\n",
    "    clf.fit(x_train_oh.iloc[train_indices, 1:], x_train_oh.iloc[train_indices, 0])\n",
    "    pred = clf.predict(x_train_oh.iloc[test_indices, 1:])\n",
    "    #print(clf.score(x_train_oh.iloc[test_indices, 1:], x_train_oh.iloc[test_indices, 0]))\n",
    "    f1_scores.append(f1_score(pred, x_train_oh.iloc[test_indices, 0]))\n",
    "    print(f1_score(pred, x_train_oh.iloc[test_indices, 0]))\n",
    "print(\"Mean F1 score:\", np.array(f1_scores).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot convergence of solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train_oh.iloc[:, 1:], x_train_oh['Active'])\n",
    "pred = clf.predict(x_test_oh)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "...   ..\n",
      "47995  0\n",
      "47996  0\n",
      "47997  0\n",
      "47998  0\n",
      "47999  0\n",
      "\n",
      "[48000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pred) \n",
    "print(df)\n",
    "df.to_csv('out.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  1\n",
      "6  0\n",
      "7  0\n",
      "8  0\n",
      "9  0\n",
      "[0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:10])\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search to find parameters that give best F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_size = int(0.006 * x_train_oh.shape[0])\n",
    "l2_size = int(0.008 * x_train_oh.shape[0])\n",
    "\n",
    "mlp = MLPClassifier(random_state=1, alpha=1e-3, hidden_layer_sizes=(l1_size, l2_size), max_iter=100, solver='adam', activation='tanh')\n",
    "\n",
    "# All parameters we want to try:\n",
    "parameter_space = {\n",
    "    #'hidden_layer_sizes': [(60, 80), (50, 80), (70, 80), (60, 70), (60, 90)],\n",
    "    #'activation': ['tanh', 'relu', 'logistic'],\n",
    "    #'solver': ['sgd', 'adam'],\n",
    "    'alpha': [1e-3, 1e-2, 1e-4],\n",
    "}\n",
    "\n",
    "# 10000 * 0.006\n",
    "\n",
    "# Do grid search over all parameter options:\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5, scoring='f1')\n",
    "clf.fit(x_train_oh.iloc[:, 1:], x_train_oh['Active'])\n",
    "print('Parameters', clf.best_params_, \"gives best score:\", clf.best_score_)\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([509.57949848, 157.87978411, 489.60818777]), 'std_fit_time': array([ 2.98684811,  3.92541923, 63.42419792]), 'mean_score_time': array([0.48849678, 0.39324956, 0.36429005]), 'std_score_time': array([0.03496291, 0.0267419 , 0.1384439 ]), 'param_activation': masked_array(data=['tanh', 'relu', 'logistic'],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'activation': 'tanh'}, {'activation': 'relu'}, {'activation': 'logistic'}], 'split0_test_score': array([0.86178862, 0.80911681, 0.81564246]), 'split1_test_score': array([0.86178862, 0.81609195, 0.82085561]), 'split2_test_score': array([0.83661972, 0.85553997, 0.80058224]), 'split3_test_score': array([0.86072423, 0.84094053, 0.80504909]), 'split4_test_score': array([0.84475524, 0.81818182, 0.75375375]), 'mean_test_score': array([0.85313529, 0.82797422, 0.79917663]), 'std_test_score': array([0.01049134, 0.01743948, 0.02383611]), 'rank_test_score': array([1, 2, 3], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "#  \"the optimal size of the hidden layer is usually between the size of the input and size of the output layers\"\n",
    "#  \"number of neurons = 0.005 * number of samples?\" 2/3 size of input is also usual\n",
    "\n",
    "# Easy: 0.607427055703\n",
    "# Medium: 0.852643419573\n",
    "# Hard: 0.89591280654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
